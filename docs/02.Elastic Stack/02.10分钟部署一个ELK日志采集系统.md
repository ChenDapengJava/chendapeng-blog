---
author:
  name: 行百里er
title: 10分钟部署一个ELK日志采集系统
titleTag: 原创
date: 2021-05-22 22:40:37
permalink: /pages/37c841/
categories: 
  - 分布式
  - Elastic Stack
tags: 
  - 日志
  - Elasticsearch
  - Logstash
  - Kibana
---

作者：行百里er

博客：[https://chendapeng.cn](https://chendapeng.cn)
:::tip
这里是 行百里er 的博客：行百里者半九十，凡事善始善终，吾将上下而求索！
:::

> ELK（Elasticsearch，Logstash，Kibana），用来收集日志还有进行日志分析，最后通过可视化UI进行展示。在大量日志产生的项目场景中，ELK是收集、分析日志的利器！
>
> 在 [这些Elasticsearch 7.10部署的问题，你遇到过吗](https://t.1yb.co/qudv) 这篇文章中，我已经部署过Elasticsearch了，本次导航将完成Logstash和Kibana的部署，并写一个SpringBoot小项目演示ELK的日志收集。

![](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/c30a1caebb8b44df980540aa25d2fbb4~tplv-k3u1fbpfcp-zoom-1.image)


## 安装Logstash

ELK三大组件的安装都很简单，几行命令就能搞定：

```
wget https://artifacts.elastic.co/downloads/logstash/logstash-7.10.2-linux-x86_64.tar.gz

tar -zxvf logstash-7.10.2-linux-x86_64.tar.gz
```
前面我们安装的Elasticsearch版本是7.10.2，所以Logstash和接下来要安装的Kibana都要安装`7.10.2`这个版本。

解压完成以后，为了启动时不每次进入到Logstash家目录，我们来配置一下环境变量：

```
vi ~/.bash_profile
# 在后面添加
export LOGSTASH_HOME=/home/elastic/logstash-7.10.2
export PATH=$PATH:$LOGSTASH_HOME/bin
```

> 关于版本问题，ELK令我感觉很爽的一点就是Elastic Stack中的Elasticsearch、Logstash、Kibana这些版本号都是一致的，这其实省去了很多麻烦。
>
> 还有下载的时候，如果想下载其他版本，直接在链接上改`版本号`就可以下载到对应版本的文件。

![](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/d2434f85dda349db8420891740f4a9b1~tplv-k3u1fbpfcp-zoom-1.image)

拷贝一份`$LOGSTASH_HOME/config/logstash-sample.conf`配置文件，命名为`logstash-app-search.conf`，修改其内容为：

```
input {
  tcp {
    # Logstash 作为服务
    mode => "server"
    host => "192.168.242.120"
    # 开放9001端口进行采集日志
    port => 9001
    # 编解码器
    codec => json_lines
  }
}

output {
  elasticsearch {
    # 配置ES的地址
    hosts => ["http://192.168.242.120:9200"]
    # 在ES里产生的index的名称
    index => "app-search-log-collection-%{+YYYY.MM.dd}"
    #user => "elastic"
    #password => "changeme"
  }
  stdout {
    codec => rubydebug
  }
}
```

启动Logstash：

```
logstash -f $LOGSTASH_HOME/config/logstash-app-search.conf

# 后台启动
# nohup logstash -f $LOGSTASH_HOME/config/logstash-app-search.conf &
```



## 安装Kibana

依然很easy：
```
# 下载
wget https://artifacts.elastic.co/downloads/kibana/kibana-7.10.2-linux-x86_64.tar.gz

# 解压
tar -zxvf kibana-7.10.2-linux-x86_64.tar.gz

# 重命名
mv kibana-7.10.2-linux-x86_64.tar.gz kibana-7.10.2

# 配置环境变量
# 编辑 ~/.bash_profile
# 最终ELK的环境变量配置
export ES_HOME=/home/elastic/elasticsearch-7.10.2
export KIBANA_HOME=/home/elastic/kibana-7.10.2
export LOGSTASH_HOME=/home/elastic/logstash-7.10.2
export PATH=$PATH:$ES_HOME/bin:$KIBANA_HOME/bin:$LOGSTASH_HOME/bin
# 使之生效
source ~/.bash_profile
```

先修改`$KIBANA_HOME/config/kibana.yml`配置文件的下面几项：

```
# Logstash端口
server.port: 5601
# Logstash的IP地址
server.host: "192.168.242.120"
# ES实例URL
elasticsearch.hosts: ["http://192.168.242.120:9200"]
```

直接使用如下命令（配置了环境变量的前提下）启动：

```sh
kibana
```

![Kibana启动日志](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/8d468484f2d94a0e86a754a3ba203793~tplv-k3u1fbpfcp-zoom-1.image)

启动成功，访问`http://192.168.242.120:5601`：

![Kibana首页](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/97f9925cb4ad48f4a2f39cc817d1cbef~tplv-k3u1fbpfcp-zoom-1.image)

## 使用ELK收集SpringBoot项目的Logback日志

主要看一下SpringBoot的日志配置文件`logback-spring.xml`：

```xml
<?xml version="1.0" encoding="UTF-8"?>
<configuration>

    <appender name="LOGSTASH" class="net.logstash.logback.appender.LogstashTcpSocketAppender">
        <!-- 在logstash启动文件logstash-app-search.conf中配置的IP地址和端口 -->
        <destination>192.168.242.120:9001</destination>
        <encoder charset="UTF-8" class="net.logstash.logback.encoder.LogstashEncoder" />
    </appender>

    <root level="INFO">
        <appender-ref ref="LOGSTASH" />
        <appender-ref ref="CONSOLE" />
    </root>
</configuration>
```
这个配置我是直接从`logstash-logback-encoder`这个项目的GitHub上拷贝过来的，改了其中的IP地址和端口。

> GitHub地址：
>
> [https://github.com/logstash/logstash-logback-encoder](https://github.com/logstash/logstash-logback-encoder)

启动SpringBoot服务：

![](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/f28a7a5547ee4f8083c444cee3fe4ebf~tplv-k3u1fbpfcp-zoom-1.image)

有错误信息，没有启动成功，这时候我们猜想一下，Logstash的日志中应该会显示这段错误日志，看一下：

![](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/b70c2340bcbd432abd8afcfca0f18487~tplv-k3u1fbpfcp-zoom-1.image)

Ok，有了，但是这样看还不如直接看SpringBoot的日志呢，没有起到ELK应有的快感，结合Kibana看，先到Index管理页面：

![](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/67009f8e16b944f195835543b7e3cf0a~tplv-k3u1fbpfcp-zoom-1.image)

这里看到了已经有在Logstash配置文件配置为index名称了。

创建一个Index Pattern：

![](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/af6389319217428ba4bb99d347402967~tplv-k3u1fbpfcp-zoom-1.image)

这时就能在Discover面板看到日志了：

![](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/d5e84992c40f4f1896317d01a10c2193~tplv-k3u1fbpfcp-zoom-1.image)

现在我们根据这个报错信息修复一下，重新启动SpringBoot。

根据报错信息可以看到，

```
Could not find an appender named [CONSOLE]
```
原因是`logback-spring.xml`配置文件中没有配置`CONSOLE`的appender，补上就行了，或者不需要控制台输出的话删掉`<appender-ref ref="CONSOLE" />`这一句。

这里为了方便在控制台看，和ELK对比，我们把输出到控制台的也加上：

```xml
<property name="pattern" value="%d{yyyy-MM-dd HH:mm:ss.SSS} [%thread] %-5level %logger{50} - %msg %n"/>
<!-- 输出到CONSOLE控制台 -->
<appender name="CONSOLE" class="ch.qos.logback.core.ConsoleAppender">
    <encoder class="ch.qos.logback.classic.encoder.PatternLayoutEncoder">
        <pattern>${pattern}</pattern>
    </encoder>
</appender>
```

启动SpringBoot，通过Kibana查看Logstash收集的日志：

![](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/390d30ebb1364cc58b2a6ecfd8327488~tplv-k3u1fbpfcp-zoom-1.image)

舒服了！

本次导航结束，休息！
![](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/79707727f98946d48902894f963eaa44~tplv-k3u1fbpfcp-zoom-1.image)

---
> 首发公众号 **行百里er** ，欢迎老铁们关注阅读指正。代码仓库 **GitHub** [github.com/xblzer/JavaJourney]([https://github.com/xblzer/JavaJourney)







